% !TeX spellcheck = fr_FR
\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion} % Adding toc entry

% Fonction de rappel
Dans un premier temps, le but de ce travail était de pouvoir détecter automatiquement des accords et notes de guitare à l'aide de différents modèles connexionnistes. Je devais donc mettre en place différentes architectures afin de comparer leurs résultats et je devais également construire mon propre ensemble de données en partant de zéro. Pour ce projet, je devais également considérer les signaux dans le monde discret et dans le monde fréquentiel. Dans un deuxième temps, je devais déterminer si les modèles étaient capables de fonctionner en temps réel.

Nous avons vu au cours de cette thèse que j'ai décidé d'implémenter et tester trois architectures, à savoir l'architecture \gls{pmc}, l'architecture \gls{rnc} et l'architecture \gls{lstmb}. Nous avons pu constater et comparer les résultats de ses trois architectures qui sont très satisfaisants. Bien que l'architecture \gls{rnc} soit celle qui ait fonctionné le moins bien, les résultats restent très corrects. Nous avons également vu que pour passer du monde discret au monde fréquentiel j'ai choisi d'utiliser la \gls{tfr} pour sa simplicité et sa rapidité. Ce qui est un facteur essentiel pour l'utilisation en temps réel. Nous avons pu observer de plus que les modèles utilisant la \gls{tfr} étaient plus efficace que ceux utilisant directement les données discrètes. Néanmoins, les résultats obtenus avec les données discrètes restent très encourageants et intéressants à explorer.

Nous avons vu aussi que j'ai dû mettre en place et construire mon propre ensemble de données. C'était très intéressant, car dans un premier temps j'avais fait mes enregistrements sans matériel spécialisé ce qui avait un impact néfaste sur mon ensemble de données, notamment au niveau du bruit dans le signal, et que cet impact se faisait ressentir sur les performances de mes modèles. J'ai ensuite eu accès à une carte son externe spécialisée dans le traitement audio, ce qui m'a permis, sur la base de mon ancien ensemble de données, d'en reconstruire un nouveau avec des données non bruitées et des structures de fichiers complètement différentes. Avec le nouvel ensemble de données, j'ai pu constater une nette amélioration dans l'entrainement des différents modèles.

Suite à ça, j'ai eu l'idée de construire un \gls{aed} afin de réduire le bruit dans les signaux que je recevais en entrée. Tout le monde n'ayant pas forcément de matériel spécialisé, il était donc nécessaire de pouvoir réduire le bruit avant de faire passer les entrées dans les modèles prédictifs. Cet \gls{aed} peut être aussi utile pour réduire les effets comme le gain, ce qui aide le modèle prédictif à prédire correctement.

Finalement, sur la base de mon ressenti d'utilisation en temps réel, nous avons pu constater que le modèle n’était pas sensible au problème du changement de phase dans les signaux et qu’il prédisait correctement les différents accords et notes joués. Nous avons également constaté que le chevauchement des fenêtres a réduit le temps de latence par deux; à savoir, un temps de latence de \textasciitilde0.023[s], ce qui rend l’utilisation en temps réel très fluide et agréable. De ce fait, le temps de latence visuelle n’est quant à lui presque pas perceptible. De plus, nous avons observé que la solution proposée, à savoir l’architecture \gls{lstmb} avec \gls{tfr} était en moyenne traversée en trois à quatre millisecondes, ce qui est bien inférieur aux cinq millisecondes souhaitées.

% Retour reflexif
En tant que passionné de musique et étant moi-même musicien c'était un réel plaisir de travailler sur ce projet. Les recherches effectuées durant ce travail m'ont apporté beaucoup de connaissances sur les notions mathématiques liées au traitement du signal. Notamment comme la fuite spectrale lors de la \gls{tfr}, l'utilisation de fenêtre pour la réduire et le théorème d'échantillonnage de Nyquist-Shanon. J'ai aussi pu approfondir mes connaissances sur les réseaux de neurones en découvrant les cellules \gls{lstm}, la normalisation par lots, les auto-encodeurs et leurs variantes ainsi que les modèles transformer. J'ai de plus pu constater l'importance et la complexité d'avoir un ensemble de données étudiées et correctement construit et donc l'importance et l'implication des "Data Scientist" dans le domaine de l'\gls{ia}. Mais ce travail m'a surtout permis de percevoir la musique dans un contexte purement physique et mathématique et de comprendre réellement ce qu'est la musique à la base.

% Ouverture
% Partie sur d'autres fonction mathématiques
Bien que la \gls{tfr} nous ait donné de bons résultats sur notre ensemble de données, il pourrait y avoir un problème avec la résolution fréquentielle. En effet, plus on descend dans les basses fréquences et plus la hauteur des notes (c'est-à-dire leur fréquence) est rapprochée (1[Hz] peut suffire à différencier un C d'un C\sh). Inversement, plus on monte dans les hautes fréquences, plus la hauteur des notes est éloignée (1[kHz] peut suffire à différencier un C d'un C\sh). On remarque donc que dans les basses fréquences nous avons besoin d'une plus grande taille de fenêtre que dans les hautes fréquences. Mais la \gls{tfr} utilise une taille fixe. Il serait donc intéressant de voir si l'on peut faire varier cette taille de fenêtre automatiquement ou utiliser d'autres fonctions comme la \gls{tfct}, la Transformée en Ondelette ou encore la \gls{tqc} et de voir si cela améliore la précision des différents modèles.

% Partie sur l'AED dans le monde des fréquences
On peut voir que j'ai construit mon \gls{aed} pour qu'il fonctionne dans le monde temporel (avec le signal discret). Il pourrait être intéressant de le considérer dans le monde des fréquences. Ainsi, on pourrait voir si la reconstruction des données non bruitées est plus efficace et plus rapide.

% Partie sur l'augmentation du dataset
Actuellement, l'ensemble de données créé se repose uniquement sur les accords à trois sons mineurs et majeurs ainsi que les notes sur l'accordage standard de la guitare. Dans un premier temps, augmenter l'ensemble de données en rajoutant des accords septièmes, diminués et augmentés pourrait permettre de voir si les architectures actuelles sont suffisantes pour différencier correctement les différents accords et notes. Ensuite, il serait intéressant de continuer l'ensemble de données dans d'autres types d'accordages afin de généraliser le problème et les modèles.

% Partie sur le transfer learning
Un autre point important est que l'ensemble de données actuel, bien qu'il soit petit, m'a pris beaucoup de temps à faire. On imagine donc bien que pour un ensemble de données qui contiendrait plusieurs types d'accords et d'accordages cela deviendrait trop lourd à construire. On pourrait donc essayer d'utiliser un modèle génératif et de faire de l'Apprentissage par Transfert (\textit{Transfer Learning} en anglais) pour pallier à ce problème. L'apprentissage par transfert consiste à utiliser un réseau préentrainé sur un ensemble de données sources qui contient des données similaires aux nôtres (par exemple un ensemble de données sur des accords et notes de piano) puis à faire du Fine Tuning avec notre ensemble de données (qu'on appelle ensemble de données de transfert) où l'on va uniquement modifier les couches denses du réseau. Ainsi, nous pouvons avoir un modèle qui va nous générer des données et de ce fait augmenter la taille de notre ensemble de données. On peut notamment penser à des modèles comme WaveNet \parencite{oord_wavenet_2016} ou encore Wave2Vec \parencite{baevski_wav2vec_2020}.

% Partie sur les modèles transformer
Pour finir, nous allons un peu parler des modèles transformer. Ce sont des modèles qui ont changé la manière dont on faisait du \gls{taln} et qui commencent à changer d'autres domaines de l'intelligence artificielle. Notamment avec "AlphaFold 2", une intelligence artificielle qui prédit la structure 3D des protéines \parencite{noauthor_alphafold_nodate}. Les modèles transformer ont été introduits en 2017 avec le document "Attention is all you need" \parencite{vaswani_attention_2017}. On pourrait donc essayer de voir si les modèles transformer peuvent apporter une amélioration dans le domaine du traitement chronologique et dans notre cas, la prédiction d'accords et de notes de musique.